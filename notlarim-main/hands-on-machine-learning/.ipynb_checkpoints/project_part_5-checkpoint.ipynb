{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "graphic-channels",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipynb.fs.full.project_part_1 import strat_train_set, strat_test_set\n",
    "from ipynb.fs.full.project_part_2 import housing\n",
    "from ipynb.fs.full.project_part_3 import housing_prepared, housing_labels, full_pipeline, cat_attribs, num_attribs\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-falls",
   "metadata": {},
   "source": [
    "# Fine Tune Your Model\n",
    "\n",
    "Let’s assume that you now have a shortlist of promising models. You now need to fine-tune them. Let’s look at a few ways you can do that.\n",
    "\n",
    "## Grid Search\n",
    "\n",
    "One option would be to fiddle with the hyperparameters manually, until you find a great combination of hyperparameter values. This would be very tedious work, and you may not have time to explore many combinations.\n",
    "\n",
    "Instead, you should get Scikit-Learn’s **`GridSearchCV`** to search for you. All you need to do is tell it which hyperparameters you want it to experiment with and what values to try out, and it will use cross-validation to evaluate all the possible combinations of hyperparameter values. For example, the following code searches for the best combination of hyperparameter values for the **`RandomForestRegressor`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "patient-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=None,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'max_features': [2, 4, 6, 8],\n",
       "                          'n_estimators': [3, 10, 30]},\n",
       "                         {'bootstrap': [False], 'max_features': [2, 3, 4],\n",
       "                          'n_estimators': [3, 10]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "param_grid = [\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]}\n",
    "]\n",
    "\n",
    "forest_reg = RandomForestRegressor()\n",
    "\n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5, \n",
    "                           scoring= 'neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adverse-johnson",
   "metadata": {},
   "source": [
    "This **`param_grid`** tells Scikit-Learn to first evaluate all $3 × 4 = 12$ combinations of **`n_estimators`** and **`max_features`** hyperparameter values specified in the first **`dict`**, then try all $2 × 3 = 6$ combinations of hyperparameter values in the second dict, but this time with the **`bootstrap`** hyperparameter set to **`False`** instead of **`True`** (which is the default value for this hyperparameter).\n",
    "\n",
    "The grid search will explore $12 + 6 = 18$ combinations of **`RandomForestRegressor`** hyperparameter values, and it will train each model 5 times (since we are using **five-fold cross validation)**. In other words, all in all, there will be $18 × 5 = 90$ rounds of training! It may take quite a long time, but when it is done you can get the best combination of parameters like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "affecting-tattoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 6, 'n_estimators': 30}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-cloud",
   "metadata": {},
   "source": [
    "Since 8 and 30 are the maximum values that were evaluated, you should probably try searching again with higher values; the score may continue to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funded-intelligence",
   "metadata": {},
   "source": [
    "You can also get the best estimator directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elegant-perspective",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=6, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=30, n_jobs=None, oob_score=False,\n",
       "                      random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-breach",
   "metadata": {},
   "source": [
    "If **`GridSearchCV`** is initialized with **`refit=True`** (which is the default), then once it finds the best estimator using cross-validation, it retrains it on the whole training set. This is usually a good idea, since feeding it more data will likely improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaptive-italy",
   "metadata": {},
   "source": [
    "And of course the evaluation scores are also available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cleared-watson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64209.54153821484 {'max_features': 2, 'n_estimators': 3}\n",
      "55177.36964723384 {'max_features': 2, 'n_estimators': 10}\n",
      "52486.73148832081 {'max_features': 2, 'n_estimators': 30}\n",
      "59457.507679278584 {'max_features': 4, 'n_estimators': 3}\n",
      "52786.020287589454 {'max_features': 4, 'n_estimators': 10}\n",
      "50472.29212297196 {'max_features': 4, 'n_estimators': 30}\n",
      "59182.43398848768 {'max_features': 6, 'n_estimators': 3}\n",
      "51982.072567783594 {'max_features': 6, 'n_estimators': 10}\n",
      "50034.32002521204 {'max_features': 6, 'n_estimators': 30}\n",
      "59440.43024002387 {'max_features': 8, 'n_estimators': 3}\n",
      "52331.76280751217 {'max_features': 8, 'n_estimators': 10}\n",
      "50318.9512193438 {'max_features': 8, 'n_estimators': 30}\n",
      "62118.48449041704 {'bootstrap': False, 'max_features': 2, 'n_estimators': 3}\n",
      "54169.294811143795 {'bootstrap': False, 'max_features': 2, 'n_estimators': 10}\n",
      "59999.955656212034 {'bootstrap': False, 'max_features': 3, 'n_estimators': 3}\n",
      "52504.53747311246 {'bootstrap': False, 'max_features': 3, 'n_estimators': 10}\n",
      "58946.97524737721 {'bootstrap': False, 'max_features': 4, 'n_estimators': 3}\n",
      "51896.13612935209 {'bootstrap': False, 'max_features': 4, 'n_estimators': 10}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres['mean_test_score'], cvres['params']):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spoken-chain",
   "metadata": {},
   "source": [
    "In this example, we obtain the best solution by setting the **`max_features`** hyperparameter to $8$ and the **`n_estimators`** hyperparameter to $30$. The RMSE score for this combination is $49,682$, which is slightly better than the score you got earlier using the default hyperparameter values (which was $50,182$). Congratulations, you have successfully fine-tuned your best model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-degree",
   "metadata": {},
   "source": [
    "## Analyze the Best Models and Their Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desirable-patch",
   "metadata": {},
   "source": [
    "You will often gain good insights on the problem by inspecting the best models. For example, the **`RandomForestRegressor`** can indicate the relative importance of each attribute for making accurate predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "filled-yahoo",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.22347587e-02, 7.68471270e-02, 4.17196690e-02, 1.72223868e-02,\n",
       "       1.73319267e-02, 1.61726339e-02, 1.67440689e-02, 3.36487642e-01,\n",
       "       6.33676269e-02, 1.08598532e-01, 5.94544626e-02, 1.29574267e-02,\n",
       "       1.42813317e-01, 1.17878662e-04, 2.55370290e-03, 5.37683986e-03])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "killing-department",
   "metadata": {},
   "source": [
    "Let’s display these importance scores next to their corresponding attribute names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "governmental-panel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.33648764224919064, 'median_income'),\n",
       " (0.14281331699728692, 'INLAND'),\n",
       " (0.10859853200493033, 'pop_per_hhold'),\n",
       " (0.08223475868455118, 'longitude'),\n",
       " (0.07684712701741128, 'latitude'),\n",
       " (0.06336762692455762, 'rooms_per_hhold'),\n",
       " (0.05945446264413106, 'bedrooms_per_room'),\n",
       " (0.04171966899932164, 'housing_median_age'),\n",
       " (0.01733192669444712, 'total_bedrooms'),\n",
       " (0.01722238684188461, 'total_rooms'),\n",
       " (0.016744068858809205, 'households'),\n",
       " (0.016172633943864183, 'population'),\n",
       " (0.01295742671474508, '<1H OCEAN'),\n",
       " (0.005376839858201243, 'NEAR OCEAN'),\n",
       " (0.0025537029043222596, 'NEAR BAY'),\n",
       " (0.00011787866234574327, 'ISLAND')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_attribs = ['rooms_per_hhold', 'pop_per_hhold', 'bedrooms_per_room']\n",
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "after-remainder",
   "metadata": {},
   "source": [
    "With this information, you may want to try dropping some of the less useful features (e.g., apparently only one **`ocean_proximity`** category is really useful, so you could try dropping the others).\n",
    "\n",
    "You should also look at the specific errors that your system makes, then try to understand why it makes them and what could fix the problem (adding extra features or getting rid of uninformative ones, cleaning up outliers, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "czech-reflection",
   "metadata": {},
   "source": [
    "## Evaluate Your System on the Test Set\n",
    "\n",
    "After tweaking your models for a while, you eventually have a system that performs sufficiently well. Now is the time to evaluate the final model on the test set. There is nothing special about this process; just get the predictors and the labels from your test set, run your **`full_pipeline`** to transform the data (call **`transform()`**, not **`fit_transform()`**—you do not want to fit the test set!), and evaluate the final model on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "super-greensboro",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "renewable-warehouse",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47762.314603153536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = strat_test_set.drop('median_house_value', axis=1)\n",
    "y_test = strat_test_set['median_house_value'].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "antique-landing",
   "metadata": {},
   "source": [
    "In some cases, such a point estimate of the generalization error will not be quite enough to convince you to launch: what if it is just 0.1% better than the model currently in production? You might want to have an idea of how precise this estimate is. For this, you can compute a 95% confidence interval for the generalization error using **`scipy.stats.t.interval()`**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "blind-dividend",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45755.20680557, 49688.41356575])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "confidence = 0.95\n",
    "\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) -1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
